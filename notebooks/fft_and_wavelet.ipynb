{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeda62bc-2b03-4599-b57a-9d384835326d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install matplotlib\n",
    "#!pip install jupyter-resource-usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d6a8da-c07c-4e60-8f5e-f0efcfb43b1d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import torch\n",
    "import os\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_force_host_platform_device_count=48\"\n",
    "import jax\n",
    "jax.config.update('jax_array', True)\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy\n",
    "import numpy as np\n",
    "# Requires 'pip install jaxwt'; jaxwt is JAX-accelerated subset of PyWavelet package (pywt)\n",
    "import jaxwt as jwt\n",
    "import pywt\n",
    "#\n",
    "from scipy import signal as sgnl\n",
    "from scipy import ndimage\n",
    "from scipy.interpolate import interp1d\n",
    "#\n",
    "from functools import partial\n",
    "#\n",
    "import time\n",
    "#\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize, LogNorm, NoNorm\n",
    "from matplotlib.cm import get_cmap\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4740111-6674-482f-b69b-e617e737ddd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 23:24:28.012912: W external/org_tensorflow/tensorflow/tsl/platform/default/dso_loader.cc:66] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/eb/sw/PyTorch/1.12.1-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/lib:/sw/eb/sw/NCCL/2.12.12-GCCcore-11.3.0-CUDA-11.7.0/lib:/sw/eb/sw/magma/2.6.2-foss-2022a-CUDA-11.7.0/lib:/sw/eb/sw/GDRCopy/2.3-GCCcore-11.3.0/lib:/sw/eb/sw/cuDNN/8.4.1.50-CUDA-11.7.0/lib:/sw/eb/sw/LibTIFF/4.3.0-GCCcore-11.3.0/lib:/sw/eb/sw/libdeflate/1.10-GCCcore-11.3.0/lib:/sw/eb/sw/zstd/1.5.2-GCCcore-11.3.0/lib:/sw/eb/sw/lz4/1.9.3-GCCcore-11.3.0/lib:/sw/eb/sw/jbigkit/2.1-GCCcore-11.3.0/lib:/sw/eb/sw/libjpeg-turbo/2.1.3-GCCcore-11.3.0/lib:/sw/eb/sw/FFmpeg/4.4.2-GCCcore-11.3.0/lib:/sw/eb/sw/FriBidi/1.0.12-GCCcore-11.3.0/lib:/sw/eb/sw/X11/20220504-GCCcore-11.3.0/lib:/sw/eb/sw/fontconfig/2.14.0-GCCcore-11.3.0/lib:/sw/eb/sw/util-linux/2.38-GCCcore-11.3.0/lib:/sw/eb/sw/freetype/2.12.1-GCCcore-11.3.0/lib:/sw/eb/sw/Brotli/1.0.9-GCCcore-11.3.0/lib:/sw/eb/sw/libpng/1.6.37-GCCcore-11.3.0/lib:/sw/eb/sw/expat/2.4.8-GCCcore-11.3.0/lib:/sw/eb/sw/x265/3.5-GCCcore-11.3.0/lib:/sw/eb/sw/LAME/3.100-GCCcore-11.3.0/lib:/sw/eb/sw/x264/20220620-GCCcore-11.3.0/lib:/sw/eb/sw/MPFR/4.1.0-GCCcore-11.3.0/lib:/sw/eb/sw/libyaml/0.2.5-GCCcore-11.3.0/lib:/sw/eb/sw/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages/numpy/core/lib:/sw/eb/sw/protobuf/3.19.4-GCCcore-11.3.0/lib:/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib:/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0/lib64:/sw/eb/sw/GMP/6.2.1-GCCcore-11.3.0/lib:/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0/lib:/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0/lib:/sw/eb/sw/libreadline/8.1.2-GCCcore-11.3.0/lib:/sw/eb/sw/ncurses/6.3-GCCcore-11.3.0/lib:/sw/eb/sw/bzip2/1.0.8-GCCcore-11.3.0/lib:/sw/eb/sw/ScaLAPACK/2.2.0-gompi-2022a-fb/lib:/sw/eb/sw/FFTW.MPI/3.3.10-gompi-2022a/lib:/sw/eb/sw/FFTW/3.3.10-GCC-11.3.0/lib:/sw/eb/sw/FlexiBLAS/3.2.0-GCC-11.3.0/lib:/sw/eb/sw/OpenBLAS/0.3.20-GCC-11.3.0/lib:/sw/eb/sw/OpenMPI/4.1.4-GCC-11.3.0/lib:/sw/eb/sw/UCC/1.0.0-GCCcore-11.3.0/lib:/sw/eb/sw/CUDA/11.7.0/nvvm/lib64:/sw/eb/sw/CUDA/11.7.0/extras/CUPTI/lib64:/sw/eb/sw/CUDA/11.7.0/lib:/sw/eb/sw/PMIx/4.1.2-GCCcore-11.3.0/lib:/sw/eb/sw/libfabric/1.15.1-GCCcore-11.3.0/lib:/sw/eb/sw/UCX/1.12.1-GCCcore-11.3.0/lib:/sw/eb/sw/libevent/2.1.12-GCCcore-11.3.0/lib:/sw/eb/sw/OpenSSL/1.1/lib:/sw/eb/sw/hwloc/2.7.1-GCCcore-11.3.0/lib:/sw/eb/sw/libpciaccess/0.16-GCCcore-11.3.0/lib:/sw/eb/sw/libxml2/2.9.13-GCCcore-11.3.0/lib:/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0/lib:/sw/eb/sw/numactl/2.0.14-GCCcore-11.3.0/lib:/sw/eb/sw/binutils/2.38-GCCcore-11.3.0/lib:/sw/eb/sw/zlib/1.2.12-GCCcore-11.3.0/lib:/sw/eb/sw/GCCcore/11.3.0/lib64:/sw/hprc/sw/ood/lib\n",
      "2023-11-10 23:24:28.012965: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "base_directory = '/scratch/group/statconsult/dataset/SmallMonolithWN/'\n",
    "output_dir = '/scratch/group/statconsult/wavelet_extraction/output/'\n",
    "device_count = jax.local_device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61edf85-5065-4cdc-9b43-6f310b556d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "print(device_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4555ef-d1c1-4cb4-bd6c-d8d4cfe0cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the original FileMaker.py\n",
    "def open_txt(filename):\n",
    "    \"\"\"\n",
    "    fs: Sample Rate\n",
    "    dt: sample step 1/fs\n",
    "    length: number of samples at each point\n",
    "    comp: the measurment component represented in the values array\n",
    "    data_shape: shape of overall array, can be ignored just used to \n",
    "                reshape array on opening from binary\n",
    "    x: X location of measurement\n",
    "    y: Y location of measurement\n",
    "    z: Z location of measurement\n",
    "    values: All values from file, row index corresponds to location\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        info = f.read(128).decode('ascii').split('\\n')\n",
    "        data_dict = {'fs': eval(info[0]), \n",
    "                     'dt': eval(info[1]),\n",
    "                     'length': eval(info[2]), \n",
    "                     'comp': info[3],\n",
    "                     'data_shape': eval(info[4])}\n",
    "        num_locs = eval(info[4])[0]\n",
    "        coords = jnp.frombuffer(f.read(), jnp.float16, count = (3*num_locs)).reshape(num_locs, 3)\n",
    "        f.seek(128)\n",
    "        data = jnp.frombuffer(f.read(), jnp.float16, offset = 2*448)\n",
    "    data = data.reshape(data_dict['data_shape'])\n",
    "    data_dict['x'] = coords[:, 0]\n",
    "    data_dict['y'] = coords[:, 1]\n",
    "    data_dict['z'] = coords[:, 2]\n",
    "    data_dict['values'] = data\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc0d5db-a50e-42e7-a09a-c6b7e610a364",
   "metadata": {},
   "source": [
    "For a given experimental setting (fixed voltage, cut state, torque, etc); we have data of a shape that looks like:\n",
    "\n",
    "(number of signals, number of components, length of signals)\n",
    "\n",
    "In our data, the number of signals is the number of spatial locations (about 105), the length is the number of time steps (about 10 million), and the number of components is 3 (for x, y, and z without doing a transform)\n",
    "\n",
    "Here, we examine doing a discrete wavelet transform for each signal and component. We summarize the resulting coefficients with a variety of different statistics in order to effectively 'compress' the information down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e4dbb9d-a4c5-40f8-8d83-61ca6c30d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelet analysis #\n",
    "@jax.jit\n",
    "def calc_energy(coeff_array):\n",
    "    return jnp.log2(jnp.mean(jnp.square(coeff_array), axis=-1)+1e-4)\n",
    "\n",
    "@jax.jit\n",
    "def compressed_features(coeff_array):\n",
    "    median = jnp.nanpercentile(coeff_array, 50, axis=-1)\n",
    "    std = jnp.nanstd(coeff_array, axis=-1)\n",
    "    perc05 = jnp.nanpercentile(coeff_array, 5, axis=-1)\n",
    "    perc25 = jnp.nanpercentile(coeff_array, 25, axis=-1)\n",
    "    perc75 = jnp.nanpercentile(coeff_array, 75, axis=-1)\n",
    "    perc95 = jnp.nanpercentile(coeff_array, 95, axis=-1)\n",
    "    #perc_crosses_zero = (jnp.count_nonzero(jnp.diff(coeff_array > 0)))/coeff_array.shape[0]\n",
    "    energy = calc_energy(coeff_array)\n",
    "    return jnp.stack([median, std, perc05, perc25, perc75, perc95, energy], axis=-1)\n",
    "\n",
    "@jax.jit\n",
    "def extract_wavelet_coeffs(signal, waveletname = 'db32', level = 16):\n",
    "    coeffs = jwt.wavedec(signal, waveletname, level = level)\n",
    "    features = jnp.concatenate([compressed_features(coeff) for coeff in coeffs], axis=-1)\n",
    "    return features\n",
    "\n",
    "@partial(jax.jit, static_argnums = 2)\n",
    "def calc_hurst_exponent(signal, waveletname = 'haar', level = 5):\n",
    "    coeffs = jwt.wavedec(signal, waveletname, level = level)\n",
    "    energies = jnp.array([calc_energy(coeff) for coeff in coeffs]).at[1:].get()\n",
    "    print(energies)\n",
    "    x = jnp.arange(1, level+1, dtype = jnp.dtype(jnp.float32))\n",
    "    ls_fit = jnp.polyfit(x, energies, 1)\n",
    "    slope = ls_fit.at[0].get()\n",
    "    hurst = -0.5*(slope + 1)\n",
    "    return hurst, x, energies, ls_fit\n",
    "    \n",
    "\n",
    "extract_all_wavelet_coeffs = jax.pmap(extract_wavelet_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea124c94-e828-4aa6-9a25-be9d0157d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_from_txt(filename, num_devices = 8):\n",
    "    data_dict = open_txt(filename)\n",
    "    x_loc_vec = data_dict['x']\n",
    "    y_loc_vec = data_dict['y']\n",
    "    num_locations = data_dict['values'].shape[0]\n",
    "\n",
    "    num_full_batches = num_locations//num_devices\n",
    "    ragged_batch_size = num_locations % num_devices\n",
    "    full_batch_dim = num_full_batches*num_devices\n",
    "\n",
    "    full_batch_coeffs = extract_all_wavelet_coeffs(data_dict['values'][:full_batch_dim].reshape(num_devices,num_full_batches,-1)).reshape(full_batch_dim,-1)\n",
    "    ragged_batch_coeffs = extract_all_wavelet_coeffs(data_dict['values'][full_batch_dim:].reshape(ragged_batch_size,1,-1)).reshape(ragged_batch_size,-1)\n",
    "    wavelet_coeffs = jnp.concatenate([full_batch_coeffs, ragged_batch_coeffs], axis=0)\n",
    "    return jnp.concatenate([x_loc_vec.reshape(-1,1), y_loc_vec.reshape(-1,1), wavelet_coeffs], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8261cd32-fa73-4274-8e3d-cc6dc6757412",
   "metadata": {},
   "source": [
    "The above returns an array of size (number of locations, number of extracted features); combine with the other 2 components of motion to get \n",
    "(nlocs, n_extracted*3)\n",
    "\n",
    "Then, we have a standard tabular data set! Stick whatever other predictors / responses you want and fit any out of the box model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc01dd00-c5a6-4b9a-9f87-2e2c47e76a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device_count = jax.local_device_count()\n",
    "#test_feats = create_features_from_txt('/scratch/group/statconsult/dataset/SmallMonolithWN/RoughCut/480 lbin txt/Hanging_480lbin_ampVolts10_x.txt', num_devices = device_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93b1c266-a2f6-41b8-b83d-6bdf7eb03d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_filetree(\n",
    "    extraction_function: Callable[[Path], np.ndarray],\n",
    "    *,\n",
    "    parent_directory: Path | None = None,\n",
    "    target_extension: str = \"*.npy\",\n",
    "):\n",
    "    if parent_directory is None:\n",
    "        raise ValueError(\"parent_directory must be specified\")\n",
    "    for dirpath, dirnames, filenames in os.walk(parent_directory):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(target_extension):\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                if \"Horizontal\" in filepath:\n",
    "                    continue\n",
    "                if \"NoTorque\" in filepath:\n",
    "                    continue\n",
    "                filepath = Path(filepath)\n",
    "                yield extraction_function(filepath)\n",
    "\n",
    "def extraction_func(filepath):\n",
    "    processed_features = create_features_from_txt(filepath, device_count)\n",
    "    cut_state = str(filepath.parent.parent).split('/')[-1]\n",
    "    output_filename = str(filepath).split('/')[-1].split('.')[0] + '.npy'\n",
    "    if not os.path.exists(os.path.join(output_dir, cut_state)):\n",
    "        os.makedirs(os.path.join(output_dir, cut_state))\n",
    "    target = os.path.join(output_dir, cut_state, output_filename)\n",
    "    jnp.save(target, processed_features)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9fd7a2-4bff-432b-b80e-06e249b3c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(walk_filetree(extraction_func, parent_directory = base_directory, target_extension = \".txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f5c5cb-96e3-4843-babb-6784eeb11383",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = os.environ['SLURM_JOB_ID']\n",
    "print(job_id)\n",
    "time.sleep(10)\n",
    "os.system('scancel ' + job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdce2965-1186-4ac8-8aed-9c8513f8c9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
